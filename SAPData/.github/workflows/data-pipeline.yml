name: School Data Ingestion Pipeline

on:
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *"   # every day at 06:00 UTC

jobs:
  ingest:
    name: Ingest Raw Data & Build Warehouse
    runs-on: ubuntu-latest

    env:
      PGHOST: ${{ secrets.PGHOST }}
      PGUSER: ${{ secrets.PGUSER }}
      PGPASSWORD: ${{ secrets.PGPASSWORD }}
      PGDATABASE: ${{ secrets.PGDATABASE }}
      PGPORT: ${{ secrets.PGPORT }}

    steps:
      # ==============================
      # 1. Checkout repo
      # ==============================
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: true

      # ==============================
      # 2. Install PostgreSQL client
      # ==============================
      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      # ==============================
      # 3. Install .NET SDK
      # ==============================
      - name: Install .NET SDK
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: "8.0.x"

      # ==============================
      # 4. Install PowerShell
      # ==============================
      - name: Install PowerShell
        run: |
          sudo apt-get update
          sudo apt-get install -y powershell

      # ==============================
      # 5. Download raw data files
      # ==============================
      - name: Download raw data files
        shell: pwsh
        run: |
          pwsh SAPData/scripts/download-raw-data.ps1 `
            -ConfigFile "SAPData/raw_sources.json" `
            -RawFolder "SAPData/Data/Raw"

      # ==============================
      # 6. Compute hashes
      # ==============================
      - name: Check for data changes
        id: hashcheck
        shell: pwsh
        run: |
          $result = pwsh SAPData/scripts/compute-hashes.ps1 `
                        -RawFolder "SAPData/Data/Raw" `
                        -HashFolder "SAPData/Hashes" `
                        -CompareOnly
          echo "changed=$result" >> $GITHUB_OUTPUT

      # ==============================
      # 7. Early exit if unchanged
      # ==============================
      - name: Stop workflow if no new data
        if: steps.hashcheck.outputs.changed == 'UNCHANGED'
        run: |
          echo "No raw data changed. Exiting early."
          exit 0

      # ==============================
      # 8. Build and Run the SQL Generator Tool
      # ==============================
      - name: Build SQL Generator
        if: steps.hashcheck.outputs.changed == 'CHANGED'
        working-directory: SAPData
        run: |
          dotnet build SAPData.sln --configuration Release

      - name: Generate Raw SQL Scripts
        if: steps.hashcheck.outputs.changed == 'CHANGED'
        working-directory: SAPData
        run: |
          dotnet run --project SAPData/SAPData.csproj
          echo "Generated raw SQL scripts."

      # ==============================
      # 9. Run the ETL SQL pipeline
      # ==============================
      - name: Run ETL pipeline
        if: steps.hashcheck.outputs.changed == 'CHANGED'
        working-directory: SAPData
        run: |
          echo "Running ETL because data changed..."
          psql -v ON_ERROR_STOP=1 -f sql/run-all.sql

      # ==============================
      # 10. Commit updated hashes
      # ==============================
      - name: Commit updated hashes
        if: steps.hashcheck.outputs.changed == 'CHANGED'
        run: |
          git config --global user.email "actions@github.com"
          git config --global user.name "GitHub Actions"
          git add SAPData/hashes/*.hash
          git commit -m "Update raw data hashes" || echo "No changes to commit"
          git push || echo "Nothing to push"
