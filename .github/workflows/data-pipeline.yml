name: School Data Ingestion Pipeline

on:
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *"   # every day at 06:00 UTC

permissions:
  contents: write
  id-token: write   # required if using OIDC with azure/login

jobs:
  ingest:
    name: Ingest Raw Data & Build Warehouse
    runs-on: ubuntu-latest
    environment: test

    env:
      # Blob (currently from GitHub secrets)
      AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
      AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}

      # Sensitive source URL (ONE endpoint in GitHub secrets)
      SENSITIVE_DATASET_URL: ${{ secrets.SENSITIVE_DATASET_URL }}

      # Konduit / AKS settings (also in GitHub secrets)
      AKS_RESOURCE_GROUP: ${{ secrets.AKS_RESOURCE_GROUP }}
      AKS_CLUSTER_NAME: ${{ secrets.AKS_CLUSTER_NAME }}
      AKS_NAMESPACE: ${{ secrets.AKS_NAMESPACE }}
      KONDUIT_APP_NAME: ${{ secrets.KONDUIT_APP_NAME }}

    steps:
      # ==============================
      # 1. Checkout repo
      # ==============================
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: true

      # ==============================
      # 2. Install dependencies
      # ==============================
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            postgresql-client \
            powershell \
            unzip

      - name: Install .NET SDK
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: "8.0.x"

      - name: Install Azure CLI
        run: |
          curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

      # ==============================
      # 3. Azure login (needed for az aks get-credentials)
      # ==============================
      - name: Azure login (OIDC)
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      # ==============================
      # 4. AKS access + konduit install
      # ==============================
      - name: Install kubectl (pinned)
        shell: bash
        run: |
          set -euo pipefail
          KUBECTL_VERSION="v1.29.8"
          curl -fsSLo kubectl "https://dl.k8s.io/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl"
          sudo install -m 0755 kubectl /usr/local/bin/kubectl
          kubectl version --client=true

      - name: Install kubelogin (pinned)
        shell: bash
        run: |
          set -euo pipefail
          KUBELOGIN_VERSION="v0.1.6"
          curl -fsSLo kubelogin.zip "https://github.com/Azure/kubelogin/releases/download/${KUBELOGIN_VERSION}/kubelogin-linux-amd64.zip"
          unzip -q kubelogin.zip
          sudo install -m 0755 bin/linux_amd64/kubelogin /usr/local/bin/kubelogin
          kubelogin --version

      - name: Configure AKS credentials
        shell: bash
        run: |
          set -euo pipefail
          az aks get-credentials --overwrite-existing -g "${AKS_RESOURCE_GROUP}" -n "${AKS_CLUSTER_NAME}"
          kubelogin convert-kubeconfig -l azurecli

      - name: Download konduit.sh
        shell: bash
        run: |
          set -euo pipefail
          curl -fsSL https://raw.githubusercontent.com/DFE-Digital/teacher-services-cloud/main/scripts/konduit.sh \
            -o "$GITHUB_WORKSPACE/konduit.sh"
          chmod +x "$GITHUB_WORKSPACE/konduit.sh"
          ls -la "$GITHUB_WORKSPACE/konduit.sh"

      # ==============================
      # 5. Ensure Blob container exists (idempotent)
      # ==============================
      - name: Ensure Blob container exists
        shell: pwsh
        run: |
          az storage container create `
            --name $env:AZURE_STORAGE_CONTAINER `
            --connection-string $env:AZURE_STORAGE_CONNECTION_STRING `
            --public-access off | Out-Null

      # ==============================
      # 6. Download source data and store latest versions in Blob
      #
      # LOGIC
      # - GIAS: 3 sensitive URLs, resolved by yyyyMMdd backtracking.
      #   * Url field in raw_sources.json contains a secret *token* that maps to an env var secret.
      #   * One GIAS file is a ZIP and must be UNZIPPED before upload.
      # - EES: only versioned API datasets are in raw_sources.json (DataSetId set, Url blank).
      # - Unversioned/historical dataset files are manually uploaded as a one-off exercise and stored in BLOB storage.
      #
      # Tracks state in versions.json
      # Outputs:
      #   changed=True/False
      #   latest_files={ key : filename }
      # ==============================
      - name: Version datasets from raw_sources.json and upload to Blob
        id: version
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"

          $conn = $env:AZURE_STORAGE_CONNECTION_STRING
          $container = $env:AZURE_STORAGE_CONTAINER
          $manifestBlobName = "versions.json"

          $sourcesPathRepo = "SAPData/raw_sources.json"
          if (-not (Test-Path $sourcesPathRepo)) {
            throw "Could not find $sourcesPathRepo in the repo."
          }

          # Separate working dir (do NOT mix with generator input dir)
          $workDir = "SAPData/Work/Versioning"
          New-Item -ItemType Directory -Force -Path $workDir | Out-Null

          # -----------------------------
          # Load sources (robust: array or single object)
          # -----------------------------
          $sourcesRaw = Get-Content $sourcesPathRepo -Raw | ConvertFrom-Json
          if ($null -eq $sourcesRaw) { throw "raw_sources.json parsed to null." }
          if ($sourcesRaw -isnot [System.Array]) { $sourcesRaw = @($sourcesRaw) }

          # Normalize to objects with stable key + metadata
          $sources = @()
          foreach ($s in $sourcesRaw) {
            $type     = [string]$s.Type
            $sub      = [string]$s.Subtype
            $year     = [string]$s.Year
            $u        = [string]$s.Url
            $org      = [string]$s.SourceOrg
            $dsid     = [string]$s.DataSetId
            $fileType = ([string]$s.FileType).ToLowerInvariant()

            if ([string]::IsNullOrWhiteSpace($type) -or
                [string]::IsNullOrWhiteSpace($sub)  -or
                [string]::IsNullOrWhiteSpace($year) -or
                [string]::IsNullOrWhiteSpace($org)) {
              throw "Each entry in raw_sources.json must include Type, Subtype, Year, SourceOrg. Offending entry: $($s | ConvertTo-Json -Compress)"
            }

            if ([string]::IsNullOrWhiteSpace($fileType)) { $fileType = "csv" }
            if ($fileType -ne "csv" -and $fileType -ne "zip") {
              throw "FileType must be 'csv' or 'zip'. Offending entry: $($s | ConvertTo-Json -Compress)"
            }

            $composite = "${type}_${sub}_${year}"
            $safeKey = ($composite -replace '[^a-zA-Z0-9_\-\.]', '_').ToLowerInvariant()

            $sources += [pscustomobject]@{
              key       = $safeKey
              url       = $u
              type      = $type
              subtype   = $sub
              year      = $year
              sourceOrg = $org
              dataSetId = $dsid
              fileType  = $fileType
            }
          }

          if ($sources.Count -eq 0) { throw "No sources found in raw_sources.json" }
          Write-Host "Loaded $($sources.Count) sources."

          # -----------------------------
          # Load manifest from Blob (if present)
          # -----------------------------
          $manifestPath = Join-Path $workDir "versions.json"
          $manifest = @{}

          $manifestExists = az storage blob exists `
            --container-name $container `
            --name $manifestBlobName `
            --connection-string $conn | ConvertFrom-Json

          if ($manifestExists.exists -eq $true) {
            az storage blob download `
              --container-name $container `
              --name $manifestBlobName `
              --file $manifestPath `
              --connection-string $conn `
              --overwrite true | Out-Null

            $manifest = Get-Content $manifestPath -Raw | ConvertFrom-Json -AsHashtable
          }

          # -----------------------------
          # Helpers
          # -----------------------------
          function Get-LondonDateYyyyMmDd([int]$daysAgo = 0) {
            $tz = [TimeZoneInfo]::FindSystemTimeZoneById("Europe/London")
            $nowLondon = [TimeZoneInfo]::ConvertTime([DateTimeOffset]::UtcNow, $tz).DateTime.Date
            return $nowLondon.AddDays(-$daysAgo).ToString("yyyyMMdd")
          }

          function Try-Head([string]$testUrl) {
            try {
              $h = Invoke-WebRequest -Method Head -Uri $testUrl -UseBasicParsing
              return @{
                ok   = $true
                etag = $h.Headers.ETag
                len  = $h.Headers.'Content-Length'
                lm   = $h.Headers.'Last-Modified'
              }
            } catch {
              return @{ ok = $false; etag = $null; len = $null; lm = $null }
            }
          }

          function Try-RangeGet([string]$testUrl) {
            try {
              $g = Invoke-WebRequest -Method Get -Uri $testUrl -Headers @{ Range = "bytes=0-0" } -UseBasicParsing
              return @{
                ok   = $true
                etag = $g.Headers.ETag
                len  = $g.Headers.'Content-Length'
                lm   = $g.Headers.'Last-Modified'
              }
            } catch {
              return @{ ok = $false; etag = $null; len = $null; lm = $null }
            }
          }

          function New-EesFileName([string]$type, [string]$subtype, [string]$year, [string]$version) {
            $base = "${type}_${subtype}_${year}"
            $safe = ($base -replace '[^a-zA-Z0-9_\-\.]', '_').ToLowerInvariant()
            return "${safe}_v${version}.csv"
          }

          function Get-EnvVarRequired([string]$name) {
            $v = [Environment]::GetEnvironmentVariable($name)
            if ([string]::IsNullOrWhiteSpace($v)) {
              throw "Required environment variable/secret '$name' is not set."
            }
            return $v
          }

          function Resolve-GiasTemplateFromToken([string]$token) {
            # raw_sources uses placeholders like:
            #   "__SECRET_URL__"
            #   "__SECRET_ESTABLISHMENT_LINKS_URL__"
            #   "__SECRET_MAT_LINKS_URL__"
            # We map token -> env var secret:
            #   __SECRET_URL__                    -> SENSITIVE_DATASET_URL
            #   __SECRET_ESTABLISHMENT_LINKS_URL__-> SENSITIVE_ESTABLISHMENT_LINKS_URL
            #   __SECRET_MAT_LINKS_URL__          -> SENSITIVE_MAT_LINKS_URL
            if ([string]::IsNullOrWhiteSpace($token)) { throw "GIAS Url token was blank." }

            $t = $token.Trim()

            switch ($t) {
              "__SECRET_URL__" { return Get-EnvVarRequired "SENSITIVE_DATASET_URL" }
              "__SECRET_ESTABLISHMENT_LINKS_URL__" { return Get-EnvVarRequired "SENSITIVE_ESTABLISHMENT_LINKS_URL" }
              "__SECRET_MAT_LINKS_URL__" { return Get-EnvVarRequired "SENSITIVE_MAT_LINKS_URL" }
              default {
                throw "Unknown GIAS secret token '$t'. Add a mapping in Resolve-GiasTemplateFromToken()."
              }
            }
          }

          function Get-FirstFileFromZip([string]$zipPath, [string]$outDir) {
            # Extract exactly one "data file" from the zip.
            # Preference: first *.csv; otherwise first non-directory entry.
            Add-Type -AssemblyName System.IO.Compression.FileSystem
            if (-not (Test-Path $zipPath)) { throw "Zip not found: $zipPath" }

            $zip = [System.IO.Compression.ZipFile]::OpenRead($zipPath)
            try {
              $entries = @($zip.Entries | Where-Object { -not [string]::IsNullOrWhiteSpace($_.Name) })
              if ($entries.Count -eq 0) { throw "Zip contains no files: $zipPath" }

              $pick = $entries | Where-Object { $_.Name.ToLowerInvariant().EndsWith(".csv") } | Select-Object -First 1
              if (-not $pick) { $pick = $entries | Select-Object -First 1 }

              New-Item -ItemType Directory -Force -Path $outDir | Out-Null
              $dest = Join-Path $outDir $pick.Name

              # Ensure parent folders if the entry has a path
              $destParent = Split-Path $dest -Parent
              if ($destParent) { New-Item -ItemType Directory -Force -Path $destParent | Out-Null }

              [System.IO.Compression.ZipFileExtensions]::ExtractToFile($pick, $dest, $true)
              return $dest
            } finally {
              $zip.Dispose()
            }
          }

          # -----------------------------
          # Main loop
          # -----------------------------
          $anyChanged = $false
          $manifestChanged = $false
          $latestFiles = @{}

          foreach ($src in $sources) {
            $key      = [string]$src.key
            $type     = [string]$src.type
            $sub      = [string]$src.subtype
            $year     = [string]$src.year
            $org      = [string]$src.sourceOrg
            $dsid     = [string]$src.dataSetId
            $urlToken = [string]$src.url
            $fileType = [string]$src.fileType

            if (-not $manifest.ContainsKey($key)) {
              $manifest[$key] = @{ latest = 0; lastSignature = ""; lastFileName = "" }
              $manifestChanged = $true
            }

            $prevSig = [string]$manifest[$key].lastSignature
            $latest  = [int]$manifest[$key].latest

            $forcedSignature = $null
            $signature = $null
            $finalName = $null
            $downloadUrl = $null

            $hasUrlToken = -not [string]::IsNullOrWhiteSpace($urlToken)
            $hasDsid     = -not [string]::IsNullOrWhiteSpace($dsid)

            # -------------------------------------------------
            # Branch A: GIAS (sensitive, dated URL probing)
            # - Uses Url token -> secret env var template
            # - Supports FileType csv or zip
            # - If zip: download zip, extract (csv), upload extracted file
            # -------------------------------------------------
            if ($org -eq "GIAS") {
              if (-not $hasUrlToken) { throw "GIAS entry '$key' must include Url token (e.g. __SECRET_...__)." }

              $template = Resolve-GiasTemplateFromToken $urlToken
              if ($template -notmatch "\{fileDatePostfix\}") {
                throw "GIAS secret template for '$key' must include {fileDatePostfix} placeholder."
              }

              $maxLookbackDays = 30
              if ($manifest[$key].ContainsKey("lastSuccessDate")) {
                $lastSuccess = [string]$manifest[$key].lastSuccessDate
                if ($lastSuccess -match '^\d{8}$') {
                  $tz = [TimeZoneInfo]::FindSystemTimeZoneById("Europe/London")
                  $nowLondon = [TimeZoneInfo]::ConvertTime([DateTimeOffset]::UtcNow, $tz).DateTime.Date
                  $lastDt = [DateTime]::ParseExact($lastSuccess, "yyyyMMdd", [System.Globalization.CultureInfo]::InvariantCulture)
                  $d = [int]($nowLondon - $lastDt).TotalDays
                  if ($d -gt 0) { $maxLookbackDays = [Math]::Min([Math]::Max($d, 1), 90) }
                }
              }

              $resolvedDate = $null
              $resolvedUrl  = $null
              $resolvedHdr  = $null

              for ($i = 0; $i -le $maxLookbackDays; $i++) {
                $d = Get-LondonDateYyyyMmDd -daysAgo $i
                $candidate = $template.Replace("{fileDatePostfix}", $d)

                $hdr = Try-Head $candidate
                if (-not $hdr.ok) { $hdr = Try-RangeGet $candidate }

                if ($hdr.ok) {
                  $resolvedDate = $d
                  $resolvedUrl  = $candidate
                  $resolvedHdr  = $hdr
                  break
                }
              }

              if (-not $resolvedUrl) {
                throw "GIAS file not found for today or last $maxLookbackDays days (URL hidden)."
              }

              $downloadUrl = $resolvedUrl
              $manifest[$key].lastSuccessDate = $resolvedDate

              # Keep original dated filename from URL for reference,
              # but if it's a ZIP, we will upload the extracted CSV with a deterministic name.
              $sourceFileName = [System.IO.Path]::GetFileName($downloadUrl)

              # Signature includes date + headers so same-date updates can be detected
              $parts = @("giasDate:$resolvedDate")
              if ($resolvedHdr.etag) { $parts += "etag:$($resolvedHdr.etag)" }
              if ($resolvedHdr.lm)   { $parts += "lm:$($resolvedHdr.lm)" }
              if ($resolvedHdr.len)  { $parts += "len:$($resolvedHdr.len)" }
              $forcedSignature = ($parts -join "|")

              if ($fileType -eq "zip") {
                # Upload extracted CSV using deterministic filename so downstream sees a CSV in Blob.
                # (Key is stable across runs; ZIP content changes are driven by signature above.)
                $finalName = "${key}.csv"
              } else {
                # For CSV sources, keep the original dated filename
                $finalName = $sourceFileName
              }
            }

            # -------------------------------------------------
            # Branch B: EES versioned API
            # - DataSetId present, Url blank
            # -------------------------------------------------
            if (-not $finalName -and $org -eq "EES") {
              if (-not $hasDsid -or $hasUrlToken) {
                throw "Invalid EES config for '$key': must have DataSetId set AND Url blank."
              }

              $versionsUrl = "https://api.education.gov.uk/statistics/v1/data-sets/$dsid/versions"
              $versions = Invoke-WebRequest -Uri $versionsUrl -UseBasicParsing |
                Select-Object -ExpandProperty Content | ConvertFrom-Json

              $published = @($versions.results | Where-Object { $_.status -eq "Published" })
              if ($published.Count -eq 0) { throw "No Published versions returned for datasetId '$dsid'." }

              $latestPub = $published | Sort-Object { [DateTimeOffset]$_.published } -Descending | Select-Object -First 1
              $dataSetVersion = [string]$latestPub.version

              $downloadUrl = "https://api.education.gov.uk/statistics/v1/data-sets/$dsid/csv?dataSetVersion=$dataSetVersion"
              $forcedSignature = "ees:$dsid|version:$dataSetVersion"
              $finalName = New-EesFileName -type $type -subtype $sub -year $year -version $dataSetVersion

              $manifest[$key].eesLatestVersion = $dataSetVersion
            }

            # -------------------------------------------------
            # Guardrails
            # -------------------------------------------------
            if (-not $finalName) {
              throw "Unsupported source config for '$key'. SourceOrg must be GIAS or EES and follow the new rules."
            }

            if ([string]::IsNullOrWhiteSpace($downloadUrl)) {
              throw "Internal error: downloadUrl not resolved for '$key'."
            }

            # -------------------------------------------------
            # Signature: always forced for GIAS and EES (by design)
            # -------------------------------------------------
            $signature = $forcedSignature
            if ([string]::IsNullOrWhiteSpace($signature)) {
              throw "Internal error: forced signature missing for '$key'."
            }

            $needDownloadToDecide = $false
            $isChanged = ($latest -eq 0) -or ($signature -ne $prevSig)

            if ($isChanged) {
              $tmpPath = Join-Path $workDir "${key}.download.tmp"
              try {
                Invoke-WebRequest -Uri $downloadUrl -OutFile $tmpPath -UseBasicParsing
              } catch {
                throw "Failed downloading dataset '$key' from source (URL hidden). $($_.Exception.Message)"
              }

              $uploadPath = $null

              if ($org -eq "GIAS" -and $fileType -eq "zip") {
                # Extract CSV from ZIP then upload extracted file
                $zipPath = Join-Path $workDir "${key}.zip"
                Move-Item -Force $tmpPath $zipPath

                $extractDir = Join-Path $workDir "${key}_extracted"
                if (Test-Path $extractDir) { Remove-Item $extractDir -Force -Recurse -ErrorAction SilentlyContinue }

                $extracted = Get-FirstFileFromZip -zipPath $zipPath -outDir $extractDir

                # Move extracted file to finalName (ensures stable blob name)
                $finalPath = Join-Path $workDir $finalName
                Copy-Item -Force $extracted $finalPath
                $uploadPath = $finalPath
              }
              else {
                $finalPath = Join-Path $workDir $finalName
                Move-Item -Force $tmpPath $finalPath
                $uploadPath = $finalPath
              }

              az storage blob upload `
                --container-name $container `
                --name $finalName `
                --file $uploadPath `
                --connection-string $conn `
                --overwrite | Out-Null

              $anyChanged = $true
              $manifest[$key].latest = ($latest + 1)
              $manifest[$key].lastSignature = $signature
              $manifest[$key].lastFileName = $finalName
              $latestFiles[$key] = $finalName

              Write-Host "UPDATED: $key -> $finalName"
            }
            else {
              $lastFile = [string]$manifest[$key].lastFileName
              if ([string]::IsNullOrWhiteSpace($lastFile)) { $lastFile = $finalName }
              $latestFiles[$key] = $lastFile
              Write-Host "UNCHANGED: $key remains $lastFile"
            }
          }

          # Upload manifest if anything changed OR we updated manifest metadata
          if ($anyChanged -or $manifestChanged) {
            $manifest | ConvertTo-Json -Depth 30 | Set-Content -Path $manifestPath -Encoding UTF8
            az storage blob upload `
              --container-name $container `
              --name $manifestBlobName `
              --file $manifestPath `
              --connection-string $conn `
              --overwrite | Out-Null
          }

          "changed=$anyChanged" | Out-File -FilePath $env:GITHUB_OUTPUT -Append -Encoding utf8
          $latestFilesJson = ($latestFiles | ConvertTo-Json -Depth 10 -Compress)
          "latest_files=$latestFilesJson" | Out-File -FilePath $env:GITHUB_OUTPUT -Append -Encoding utf8

      # ==============================
      # 7. Early exit if unchanged
      # ==============================
      - name: Stop workflow if no new data
        if: steps.version.outputs.changed != 'True'
        run: |
          echo "No raw data changed (based on HTTP headers/size). Exiting early."
          exit 0

      # ==============================
      # 8. Download the *latest versioned* CSVs from Blob for the generator/ETL
      # ==============================
      - name: Download latest versioned files from Blob Storage
        if: steps.version.outputs.changed == 'True'
        shell: pwsh
        env:
          LATEST_FILES: ${{ steps.version.outputs.latest_files }}
        run: |
          $ErrorActionPreference = "Stop"
          $rawDir = "SAPData/DataMap/SourceFiles"
          New-Item -ItemType Directory -Force -Path $rawDir | Out-Null
          Remove-Item "$rawDir/*" -Force -Recurse -ErrorAction SilentlyContinue

          $latest = $env:LATEST_FILES | ConvertFrom-Json -AsHashtable
          if (-not $latest -or $latest.Keys.Count -eq 0) {
            throw "LATEST_FILES output was empty."
          }

          foreach ($k in $latest.Keys) {
            $blob = [string]$latest[$k]
            if ([string]::IsNullOrWhiteSpace($blob)) {
              throw "LATEST_FILES contained an empty blob name for key '$k'"
            }

            $dest = Join-Path $rawDir $blob

            az storage blob download `
              --container-name $env:AZURE_STORAGE_CONTAINER `
              --name $blob `
              --file $dest `
              --connection-string $env:AZURE_STORAGE_CONNECTION_STRING `
              --overwrite true | Out-Null
          }

          $files = Get-ChildItem $rawDir -File
          if (-not $files) { throw "No files were downloaded from Blob to $rawDir." }

          Write-Host "Downloaded latest files:"
          $files | Select-Object Name, Length


      # ==============================
      # 8b. Normalise filenames for generator (strip _v000001 suffix where present)
      # ==============================
      - name: Normalise filenames for generator (strip _v000001 suffix where present)
        if: steps.version.outputs.changed == 'True'
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"
          $rawDir = "SAPData/DataMap/SourceFiles"

          $files = Get-ChildItem $rawDir -Filter *.csv -File
          if (-not $files) {
            throw "No CSV files found in $rawDir"
          }

          foreach ($f in $files) {
            # Only strip numeric version suffix if present: <name>_v000123.csv
            if ($f.BaseName -match '^(?<stable>.+)_v\d{6}$') {
              $stableName = $Matches['stable'] + $f.Extension
              $dest = Join-Path $rawDir $stableName

              # Copy versioned -> stable (overwrite stable)
              Copy-Item -Force $f.FullName $dest
            }
          }

          Write-Host "Normalised files present (post-copy):"
          Get-ChildItem $rawDir -Filter *.csv -File | Select-Object Name, Length

          # Remove ONLY the numeric-versioned copies; keep everything else (e.g. GIAS dated files)
          Get-ChildItem $rawDir -Filter '*_v??????.csv' -File | Remove-Item -Force


      # ==============================
      # 9. Build + Run SQL generator
      # ==============================
      - name: Build SQL Generator
        if: steps.version.outputs.changed == 'True'
        run: |
          dotnet build SAPPub.sln --configuration Release

      - name: Generate SQL Scripts
        if: steps.version.outputs.changed == 'True'
        run: |
          dotnet run --configuration Release --project SAPData/SAPData.csproj
          echo "Generated SQL scripts."

      # ==============================
      # 10. Run ETL via konduit (private DB)
      # ==============================
      - name: Run ETL pipeline via konduit
        if: steps.version.outputs.changed == 'True'
        working-directory: SAPData/Sql
        shell: bash
        run: |
          set -euo pipefail
          echo "Running ETL via konduit because data changed..."
          ls -la "$GITHUB_WORKSPACE/SAPData/Sql" || true
          "$GITHUB_WORKSPACE/konduit.sh" -n "${AKS_NAMESPACE}" -t 7200 -x \
            -i "$GITHUB_WORKSPACE/SAPData/Sql/run_all.sql" \
            "${KONDUIT_APP_NAME}" -- psql
